# ä½¿ç”¨é“å®¢äº‘çš„NVIDIA CUDAé•œåƒï¼ˆä¸­å›½é•œåƒï¼‰- ä½¿ç”¨12.6å…¼å®¹ä½ çš„é©±åŠ¨
FROM docker.m.daocloud.io/nvidia/cuda:12.6.3-cudnn-devel-ubuntu24.04

ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
# é…ç½®torch hubç¼“å­˜ç›®å½•å’Œä¿¡ä»»è®¾ç½®
ENV TORCH_HOME=/root/.cache/torch
ENV TORCH_HUB_DIR=/root/.cache/torch/hub

WORKDIR /app

ARG EXTRAS
ARG HF_PRECACHE_DIR
ARG HF_TKN_FILE

# Ubuntuæºé…ç½®ï¼ˆHTTPâ†’HTTPSæ™ºèƒ½åˆ‡æ¢ç­–ç•¥ï¼‰
RUN echo "ğŸ‡¨ğŸ‡³ é…ç½®Ubuntué•œåƒæº..." && \
    # å¤‡ä»½åŸå§‹æº
    cp /etc/apt/sources.list /etc/apt/sources.list.backup 2>/dev/null || true && \
    # ä½¿ç”¨é˜¿é‡Œäº‘é•œåƒæº
    echo 'deb http://mirrors.aliyun.com/ubuntu/ noble main restricted universe multiverse' > /etc/apt/sources.list && \
    echo 'deb http://mirrors.aliyun.com/ubuntu/ noble-updates main restricted universe multiverse' >> /etc/apt/sources.list && \
    echo 'deb http://mirrors.aliyun.com/ubuntu/ noble-backports main restricted universe multiverse' >> /etc/apt/sources.list && \
    echo 'deb http://mirrors.aliyun.com/ubuntu/ noble-security main restricted universe multiverse' >> /etc/apt/sources.list && \
    # æ¸…ç†å…¶ä»–æºé…ç½®
    rm -rf /etc/apt/sources.list.d/* 2>/dev/null || true && \
    # æ›´æ–°åŒ…åˆ—è¡¨å¹¶å®‰è£…ca-certificates
    apt-get update && \
    apt-get install -y --no-install-recommends ca-certificates && \
    # å‡çº§ä¸ºHTTPSæº
    sed -i 's|http://|https://|g' /etc/apt/sources.list && \
    apt-get update && \
    # å®‰è£…ä¾èµ–åŒ…
    apt-get install -y --no-install-recommends \
        python3 \
        python3-pip \
        python3-venv \
        ffmpeg \
        git \
        build-essential \
        python3-dev && \
    rm -rf /var/lib/apt/lists/* && \
    echo "âœ… Ubuntuæºé…ç½®å®Œæˆ"

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒå¹¶é…ç½®pipé•œåƒæº
RUN python3 -m venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"

# é…ç½®pipä½¿ç”¨ä¸­å›½é•œåƒæº
RUN echo "ğŸ‡¨ğŸ‡³ é…ç½®pipé•œåƒæº..." && \
    pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple && \
    pip config set install.trusted-host pypi.tuna.tsinghua.edu.cn && \
    pip install --upgrade pip -i https://pypi.tuna.tsinghua.edu.cn/simple && \
    echo "âœ… pipé…ç½®å®Œæˆ"

# å®‰è£…PyTorch - ä½¿ç”¨å®˜æ–¹CUDAæºç¡®ä¿ç‰ˆæœ¬å…¼å®¹æ€§
RUN echo "ğŸ‡¨ğŸ‡³ å®‰è£…PyTorch (CUDA 12.6)..." && \
    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126 && \
    echo "âœ… PyTorchå®‰è£…å®Œæˆ"

COPY . .
COPY smart_start.py /app/smart_start.py
RUN chmod +x /app/smart_start.py

# Install WhisperLiveKit directly, allowing for optional dependencies
#   Note: For gates models, need to add your HF token. See README.md
#         for more details.
RUN echo "ğŸ‡¨ğŸ‡³ å®‰è£…WhisperLiveKit..." && \
    if [ -n "$EXTRAS" ]; then \
      echo "Installing with extras: [$EXTRAS]"; \
      (pip install --no-cache-dir whisperlivekit[$EXTRAS] -i https://pypi.tuna.tsinghua.edu.cn/simple || \
       pip install --no-cache-dir whisperlivekit[$EXTRAS] -i https://pypi.mirrors.ustc.edu.cn/simple || \
       pip install --no-cache-dir whisperlivekit[$EXTRAS] -i https://repo.huaweicloud.com/repository/pypi/simple || \
       pip install --no-cache-dir whisperlivekit[$EXTRAS]); \
    else \
      echo "Installing base package only"; \
      (pip install --no-cache-dir whisperlivekit -i https://pypi.tuna.tsinghua.edu.cn/simple || \
       pip install --no-cache-dir whisperlivekit -i https://pypi.mirrors.ustc.edu.cn/simple || \
       pip install --no-cache-dir whisperlivekit -i https://repo.huaweicloud.com/repository/pypi/simple || \
       pip install --no-cache-dir whisperlivekit); \
    fi && \
    echo "âœ… WhisperLiveKitå®‰è£…å®Œæˆ"

# åˆ›å»ºç¼“å­˜ç›®å½•å¹¶è®¾ç½®æƒé™
RUN mkdir -p /root/.cache/torch/hub /root/.cache/huggingface/hub && \
    chmod -R 755 /root/.cache

# Enable in-container caching for Hugging Face models and torch hub
# Note: If running multiple containers, better to map a shared bucket. 
VOLUME ["/root/.cache/huggingface/hub", "/root/.cache/torch/hub"]

# or
# B) Conditionally copy a local pre-cache from the build context to the 
#    container's cache via the HF_PRECACHE_DIR build-arg.
#    WARNING: This will copy ALL files in the pre-cache location.

# Conditionally copy a cache directory if provided
RUN if [ -n "$HF_PRECACHE_DIR" ]; then \
      echo "Copying Hugging Face cache from $HF_PRECACHE_DIR"; \
      mkdir -p /root/.cache/huggingface/hub && \
      cp -r $HF_PRECACHE_DIR/* /root/.cache/huggingface/hub; \
    else \
      echo "No local Hugging Face cache specified, skipping copy"; \
    fi

# Conditionally copy a Hugging Face token if provided

RUN if [ -n "$HF_TKN_FILE" ]; then \
      echo "Copying Hugging Face token from $HF_TKN_FILE"; \
      mkdir -p /root/.cache/huggingface && \
      cp $HF_TKN_FILE /root/.cache/huggingface/token; \
    else \
      echo "No Hugging Face token file specified, skipping token setup"; \
    fi
    
# Expose port for the transcription server
EXPOSE 8000

ENTRYPOINT ["python3", "/app/smart_start.py"]